# ğŸ™ï¸ Speech Emotion Recognition Web App

This project combines a powerful machine learning model with a modern web interface to detect human emotions from **speech/audio input**.

---

## ğŸ§  Machine Learning Model

At the core of this system is a **fine-tuned Wav2Vec2 model**, based on the `facebook/wav2vec2-large-xlsr-53` architecture. It has been trained on the **TESS Toronto Emotional Speech Dataset** with 7 emotion classes:

> ğŸ˜ƒ Happy | ğŸ˜¡ Angry | ğŸ˜¢ Sad | ğŸ˜± Fear | ğŸ˜– Disgust | ğŸ˜² Surprise | ğŸ˜ Neutral

The model includes:
- **Wav2Vec2 Encoder** for feature extraction
- **Custom classification head** (PyTorch)
- **Preprocessing** with noise augmentation & normalization
- Exported and used via `emotion_model.pth`

---

## ğŸŒ Full-Stack Web Application

The application consists of a **FastAPI backend** and a **React.js frontend**, designed for an interactive and real-time emotion recognition experience.

### ğŸ§  Machine Learning
- `transformers==4.37.2`
- `peft==0.3.0`
- `accelerate==0.25.0`
- `torch`, `torchaudio`
- `scikit-learn`, `librosa`

### ğŸ–¥ï¸ Backend
- `FastAPI` - Lightweight and fast backend framework
- `Uvicorn` - ASGI server
- `Pydantic` - Data validation

### ğŸŒ Frontend
- `React.js` (Latest version)
- `Tailwind CSS` & `Framer Motion` for beautiful animations and transitions
- `axios` for HTTP requests
- `MediaRecorder` API to capture live audio

---

## ğŸ“ Project Structure
Speech-Emotion-Recognition/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ main.py                # FastAPI app entry point
â”‚   â”œâ”€â”€ emotion_detection.py   # Loads model, handles preprocessing & prediction
â”‚   â”œâ”€â”€ emotion_model.pth      # Fine-tuned Wav2Vec2 model
â”‚   â””â”€â”€ emotion_recognizer.py  # Audio feature extractor & real-time recognition class
    â””â”€â”€ audio_processor.py
â”‚
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   |            
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultDashboard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SpectrogramPlot.jsx     
â”‚   â”‚   â”‚   â”œâ”€â”€ EmotionBarChart.jsx     
â”‚   â”‚   â”‚   â””â”€â”€ WaveformPlot.jsx      
â”‚   â”‚   â””â”€â”€ index.js
        â”œâ”€â”€ App.jsx         # React app entry point
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json               # Frontend dependencies & scripts
â”‚
â””â”€â”€ README.md

## âš™ï¸ Features

- ğŸ§ Upload `.wav` audio files
- ğŸ™ï¸ Record live audio using mic
- ğŸ“ˆ Real-time emotion prediction
- ğŸ§  Visual feedback via animated emotion bars
- ğŸš€ Fast and responsive using modern frontend stack

---

## ğŸ› ï¸ Tech Stack

- **Backend:** FastAPI, PyTorch, Transformers (Hugging Face), Wav2Vec2
- **Frontend:** React.js, Tailwind CSS, Framer Motion
- **Model Training:** Wav2Vec2 fine-tuned with `Trainer` API from Hugging Face

---

## ğŸš€ How to Run

1. **Clone the repo:**
   ```bash
   git clone https://github.com/your-username/Speech-Emotion-Recognition.git
   cd Speech-Emotion-Recognition

## Backend setup (inside Backend/)
cd Backend
pip install -r requirements.txt
uvicorn main:app --reload

## Frontend setup (inside Frontend/)
cd Frontend
npm install
npm start